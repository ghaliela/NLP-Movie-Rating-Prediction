{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/ghaliela/transformer-model-to-predict-movie-rating?scriptVersionId=86587661\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# This R environment comes with many helpful analytics packages installed\n# It is defined by the kaggle/rstats Docker image: https://github.com/kaggle/docker-rstats\n# For example, here's a helpful package to load\n\nlibrary(tidyverse) # metapackage of all tidyverse packages\n\ndevtools::install_github(\"rstudio/reticulate\")\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nmovies_db <- read.csv(\"../input/tmdb-movie-metadata/tmdb_5000_movies.csv\")\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","execution":{"iopub.status.busy":"2022-01-30T21:06:19.564721Z","iopub.execute_input":"2022-01-30T21:06:19.566742Z","iopub.status.idle":"2022-01-30T21:07:54.872584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Transformers Initializing**","metadata":{}},{"cell_type":"code","source":"reticulate::py_install('transformers', pip = TRUE)\n\ntensorflow::tf_version()\n\nreticulate::py_module_available('transformers')\n\nlibrary(keras)\nlibrary(tensorflow)\nlibrary(dplyr)\nlibrary(tfdatasets)\n\ntransformer = reticulate::import('transformers')","metadata":{"execution":{"iopub.status.busy":"2022-01-30T21:07:54.876051Z","iopub.execute_input":"2022-01-30T21:07:54.908439Z","iopub.status.idle":"2022-01-30T21:08:16.656605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Text Processing*","metadata":{}},{"cell_type":"code","source":"data <- movies_db[1:3000,] %>% select(overview, vote_average)\nplots <- data[,1]\nratings <- data[,2]","metadata":{"execution":{"iopub.status.busy":"2022-01-30T21:08:16.659851Z","iopub.execute_input":"2022-01-30T21:08:16.661259Z","iopub.status.idle":"2022-01-30T21:08:16.690721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"library(text2vec)\n\ndf = data %>% sample_n(2000) %>% \n  data.table::as.data.table()\ndf %>% head()","metadata":{"execution":{"iopub.status.busy":"2022-01-30T21:08:16.693617Z","iopub.execute_input":"2022-01-30T21:08:16.694928Z","iopub.status.idle":"2022-01-30T21:08:17.222827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test charasters encoding\nlibrary(utf8)\nplots[!utf8_valid(plots)]","metadata":{"execution":{"iopub.status.busy":"2022-01-30T21:08:17.22571Z","iopub.execute_input":"2022-01-30T21:08:17.227027Z","iopub.status.idle":"2022-01-30T21:08:17.253849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalize text\nplots_NFC <- utf8_normalize(plots)\nsum(plots_NFC != plots)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T21:08:17.256704Z","iopub.execute_input":"2022-01-30T21:08:17.258052Z","iopub.status.idle":"2022-01-30T21:08:17.311197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split train and test dataset\nidx_train = sample.int(nrow(df)*0.8)\n\ntrain = data[1:1600,]\ntest = data[1601:2000,]","metadata":{"execution":{"iopub.status.busy":"2022-01-30T21:08:17.314058Z","iopub.execute_input":"2022-01-30T21:08:17.315353Z","iopub.status.idle":"2022-01-30T21:08:17.329925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"length(train)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T21:08:17.332748Z","iopub.execute_input":"2022-01-30T21:08:17.334129Z","iopub.status.idle":"2022-01-30T21:08:17.347923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length <- max(nchar(data$overview))\nmax_length\ntest","metadata":{"execution":{"iopub.status.busy":"2022-01-30T21:08:17.350854Z","iopub.execute_input":"2022-01-30T21:08:17.352185Z","iopub.status.idle":"2022-01-30T21:08:17.445846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# models to test\nai_m = list(\n   c('TFGPT2Model',       'GPT2Tokenizer',       'gpt2'),\n   c('TFRobertaModel',    'RobertaTokenizer',    'roberta-base'),\n   c('TFElectraModel',    'ElectraTokenizer',    'google/electra-small-generator')\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T21:08:17.448926Z","iopub.execute_input":"2022-01-30T21:08:17.450733Z","iopub.status.idle":"2022-01-30T21:08:17.462959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf$keras$backend$set_floatx('float32')\ntensorflow::tf_gpu_configured()","metadata":{"execution":{"iopub.status.busy":"2022-01-30T21:08:17.465842Z","iopub.execute_input":"2022-01-30T21:08:17.467511Z","iopub.status.idle":"2022-01-30T21:08:19.305061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hyper-parameters\nmax_len = 100L\nepochs = 5\nbatch_size = 10\n\n# create a list for model results\ngather_history = list()\n\nfor (i in 1:length(ai_m)) {\n  \n  # tokenizer\n  tokenizer = glue::glue(\"transformer${ai_m[[i]][2]}$from_pretrained('{ai_m[[i]][3]}',\n                         do_lower_case=TRUE)\") %>% \n    rlang::parse_expr() %>% eval()\n  \n  # model\n  model_ = glue::glue(\"transformer${ai_m[[i]][1]}$from_pretrained('{ai_m[[i]][3]}')\") %>% \n    rlang::parse_expr() %>% eval()\n  \n  # inputs\n  text = list()\n  # outputs\n  label = list()\n  \n  data_prep = function(data) {\n    for (i in 1:nrow(data)) {\n      \n      txt = tokenizer$encode(data[['overview']][i],max_length = max_len, \n                             truncation=T) %>% \n        t() %>% \n        as.matrix() %>% list()\n      lbl = data[['vote_average']][i] %>% t()\n      \n      text = text %>% append(txt)\n      label = label %>% append(lbl)\n    }\n    list(do.call(plyr::rbind.fill.matrix,text), do.call(plyr::rbind.fill.matrix,label))\n  }\n  \n  train_ = data_prep(train)\n  test_ = data_prep(test)\n  \n  # slice dataset\n  tf_train = tensor_slices_dataset(list(train_[[1]],train_[[2]])) %>% \n    dataset_batch(batch_size = batch_size, drop_remainder = TRUE) %>% \n    dataset_shuffle(128) %>% dataset_repeat(epochs) %>% \n    dataset_prefetch(tf$data$experimental$AUTOTUNE)\n  \n  tf_test = tensor_slices_dataset(list(test_[[1]],test_[[2]])) %>% \n    dataset_batch(batch_size = batch_size)\n  \n  # create an input layer\n  input = layer_input(shape=c(max_len), dtype='int32')\n  hidden_mean = tf$reduce_mean(model_(input)[[1]], axis=1L) %>% \n    layer_dense(64,activation = 'relu')\n  # create an output layer for Regression\n  output = hidden_mean %>% layer_dense(units=1)\n  model = keras_model(inputs=input, outputs = output)\n  \n  # compile with Mean squared error for validation and model evaluation\n  model %>% compile(optimizer= tf$keras$optimizers$Adam(learning_rate=0.1, epsilon=0.05, clipnorm=1.0),\n                    loss = tf$losses$MeanSquaredError(),\n                    metrics = tf$metrics$MeanSquaredError())\n  \n  print(glue::glue('{ai_m[[i]][1]}'))\n  # train the model\n  history = model %>% keras::fit(tf_train, epochs=epochs, #steps_per_epoch=len/batch_size,\n                validation_data=tf_test)\n  gather_history[[i]]<- history\n  names(gather_history)[i] = ai_m[[i]][1]\n}","metadata":{"execution":{"iopub.status.busy":"2022-01-30T21:08:19.308119Z","iopub.execute_input":"2022-01-30T21:08:19.309569Z","iopub.status.idle":"2022-01-30T21:32:26.265563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = sapply(1:3, function(x) {\n  do.call(rbind,gather_history[[x]][[\"metrics\"]]) %>% \n    as.data.frame() %>% \n    tibble::rownames_to_column() %>% \n    mutate(model_names = names(gather_history[x])) \n}, simplify = F) %>% do.call(plyr::rbind.fill,.) %>% \n  mutate(rowname = stringr::str_extract(rowname, 'loss|val_loss|mse|val_mse')) %>% \n  rename(epoch_1 = V1, epoch_2 = V2)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T21:32:26.26857Z","iopub.execute_input":"2022-01-30T21:32:26.269929Z","iopub.status.idle":"2022-01-30T21:32:26.316867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Metrics per epoch per model\nlibrary(dplyr)\nres  %>% \n  mutate(epoch_1 = round(epoch_1,3),epoch_2 = round(epoch_2,3))\nDT::datatable(res, options = list(dom = 't'))","metadata":{"execution":{"iopub.status.busy":"2022-01-30T21:32:26.319876Z","iopub.execute_input":"2022-01-30T21:32:26.321176Z","iopub.status.idle":"2022-01-30T21:32:26.541851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}